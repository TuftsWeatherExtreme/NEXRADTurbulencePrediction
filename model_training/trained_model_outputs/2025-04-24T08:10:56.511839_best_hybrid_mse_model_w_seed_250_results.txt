[Epoch: 1, Batch_num:   100] avg training loss per batch: 30.693[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.007[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.163[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.010[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.022[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.015[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.061[Epoch: 1, Batch_num:   800] avg training loss per batch: 1.978[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.002[Epoch: 2, Batch_num:   100] avg training loss per batch: 1.990[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.000[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.010[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.013[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.002[Epoch: 2, Batch_num:   600] avg training loss per batch: 1.982[Epoch: 2, Batch_num:   700] avg training loss per batch: 1.995[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.010[Epoch: 2, Batch_num:   900] avg training loss per batch: 1.987[Epoch: 3, Batch_num:   100] avg training loss per batch: 1.992[Epoch: 3, Batch_num:   200] avg training loss per batch: 1.960[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.064[Epoch: 3, Batch_num:   400] avg training loss per batch: 1.964[Epoch: 3, Batch_num:   500] avg training loss per batch: 1.951[Epoch: 3, Batch_num:   600] avg training loss per batch: 1.987[Epoch: 3, Batch_num:   700] avg training loss per batch: 1.972[Epoch: 3, Batch_num:   800] avg training loss per batch: 1.976[Epoch: 3, Batch_num:   900] avg training loss per batch: 1.967[Epoch: 4, Batch_num:   100] avg training loss per batch: 1.977[Epoch: 4, Batch_num:   200] avg training loss per batch: 1.971[Epoch: 4, Batch_num:   300] avg training loss per batch: 1.966[Epoch: 4, Batch_num:   400] avg training loss per batch: 1.992[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.002[Epoch: 4, Batch_num:   600] avg training loss per batch: 1.963[Epoch: 4, Batch_num:   700] avg training loss per batch: 1.970[Epoch: 4, Batch_num:   800] avg training loss per batch: 1.959[Epoch: 4, Batch_num:   900] avg training loss per batch: 1.958[Epoch: 1, Batch_num:   100] avg training loss per batch: 120.800[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.262[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.251[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.232[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.234[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.229[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.219[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.222[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.219[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.208[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.241[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.218[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.209[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.206[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.216[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.323[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.232[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.214[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.208[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.218[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.222[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.199[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.293[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.753[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.339[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.261[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.260[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.344[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.306[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.252[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.210[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.207[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.190[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.183[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.195[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.206[Epoch: 1, Batch_num:   100] avg training loss per batch: 39.627[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.241[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.226[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.217[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.210[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.196[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.215[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.195[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.185[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.196[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.246[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.190[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.182[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.208[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.182[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.185[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.174[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.182[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.206[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.185[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.184[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.182[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.175[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.188[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.172[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.163[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.179[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.194[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.177[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.158[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.167[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.178[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.175[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.163[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.156[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.179[Epoch: 1, Batch_num:   100] avg training loss per batch: 855.511[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.368[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.268[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.243[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.219[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.214[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.220[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.209[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.227[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.206[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.210[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.217[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.208[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.277[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.208[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.226[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.205[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.219[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.216[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.214[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.201[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.216[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.223[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.218[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.211[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.206[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.209[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.207[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.211[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.218[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.202[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.198[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.201[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.246[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.212[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.196[Epoch: 1, Batch_num:   100] avg training loss per batch: 1625.999[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.159[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.155[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.155[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.147[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.145[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.146[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.151[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.146[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.146[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.147[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.156[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.146[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.138[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.132[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.139[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.126[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.130[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.133[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.127[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.130[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.129[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.119[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.112[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.125[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.118[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.115[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.107[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.111[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.116[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.108[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.109[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.111[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.121[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.104[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.108[Epoch: 1, Batch_num:   100] avg training loss per batch: 101.005[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.185[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.135[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.129[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.130[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.149[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.125[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.122[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.141[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.135[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.132[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.124[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.127[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.131[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.124[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.130[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.076[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.045[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.022[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.007[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.015[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.010[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.017[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.016[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.030[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.211[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.147[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.126[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.132[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.126[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.126[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.289[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.126[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.132[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.128[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.128[Epoch: 1, Batch_num:   100] avg training loss per batch: 962.265[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.191[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.168[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.176[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.166[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.152[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.167[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.173[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.172[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.164[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.155[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.155[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.162[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.156[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.154[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.154[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.150[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.145[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.154[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.151[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.152[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.147[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.160[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.146[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.146[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.154[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.139[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.148[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.144[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.139[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.161[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.150[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.188[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.128[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.142[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.140[Epoch: 1, Batch_num:   100] avg training loss per batch: 70.028[Epoch: 1, Batch_num:   200] avg training loss per batch: 1.966[Epoch: 1, Batch_num:   300] avg training loss per batch: 1.969[Epoch: 1, Batch_num:   400] avg training loss per batch: 1.949[Epoch: 1, Batch_num:   500] avg training loss per batch: 1.955[Epoch: 1, Batch_num:   600] avg training loss per batch: 1.944[Epoch: 1, Batch_num:   700] avg training loss per batch: 1.952[Epoch: 1, Batch_num:   800] avg training loss per batch: 1.937[Epoch: 1, Batch_num:   900] avg training loss per batch: 1.946[Epoch: 2, Batch_num:   100] avg training loss per batch: 1.940[Epoch: 2, Batch_num:   200] avg training loss per batch: 1.955[Epoch: 2, Batch_num:   300] avg training loss per batch: 1.960[Epoch: 2, Batch_num:   400] avg training loss per batch: 1.942[Epoch: 2, Batch_num:   500] avg training loss per batch: 1.944[Epoch: 2, Batch_num:   600] avg training loss per batch: 1.942[Epoch: 2, Batch_num:   700] avg training loss per batch: 1.932[Epoch: 2, Batch_num:   800] avg training loss per batch: 1.936[Epoch: 2, Batch_num:   900] avg training loss per batch: 1.934[Epoch: 3, Batch_num:   100] avg training loss per batch: 1.936[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.664[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.148[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.062[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.031[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.023[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.023[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.016[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.018[Epoch: 4, Batch_num:   100] avg training loss per batch: 1.996[Epoch: 4, Batch_num:   200] avg training loss per batch: 1.980[Epoch: 4, Batch_num:   300] avg training loss per batch: 1.968[Epoch: 4, Batch_num:   400] avg training loss per batch: 1.969[Epoch: 4, Batch_num:   500] avg training loss per batch: 1.957[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.007[Epoch: 4, Batch_num:   700] avg training loss per batch: 1.976[Epoch: 4, Batch_num:   800] avg training loss per batch: 1.985[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.039[Epoch: 1, Batch_num:   100] avg training loss per batch: 446.855[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.335[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.242[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.207[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.198[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.199[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.188[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.191[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.187[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.198[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.189[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.179[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.182[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.178[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.197[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.195[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.189[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.181[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.189[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.177[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.176[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.186[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.177[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.180[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.170[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.169[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.183[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.166[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.177[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.171[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.165[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.164[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.169[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.174[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.159[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.165[Epoch: 1, Batch_num:   100] avg training loss per batch: 627.848[Epoch: 1, Batch_num:   200] avg training loss per batch: 3.585[Epoch: 1, Batch_num:   300] avg training loss per batch: 3.454[Epoch: 1, Batch_num:   400] avg training loss per batch: 3.332[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.964[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.059[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.040[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.039[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.015[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.024[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.012[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.025[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.015[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.022[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.036[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.049[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.017[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.030[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.071[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.027[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.019[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.034[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.030[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.020[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.050[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.041[Epoch: 3, Batch_num:   900] avg training loss per batch: 1.964[Epoch: 4, Batch_num:   100] avg training loss per batch: 1.993[Epoch: 4, Batch_num:   200] avg training loss per batch: 1.985[Epoch: 4, Batch_num:   300] avg training loss per batch: 1.967[Epoch: 4, Batch_num:   400] avg training loss per batch: 1.979[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.004[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.016[Epoch: 4, Batch_num:   700] avg training loss per batch: 1.988[Epoch: 4, Batch_num:   800] avg training loss per batch: 1.988[Epoch: 4, Batch_num:   900] avg training loss per batch: 1.984[Epoch: 1, Batch_num:   100] avg training loss per batch: 1048.461[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.366[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.368[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.354[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.364[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.368[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.349[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.316[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.286[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.223[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.201[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.188[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.177[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.174[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.167[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.169[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.162[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.161[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.154[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.163[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.151[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.158[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.164[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.154[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.158[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.148[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.158[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.159[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.145[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.146[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.148[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.143[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.144[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.148[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.150[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.152[Epoch: 1, Batch_num:   100] avg training loss per batch: 860.609[Epoch: 1, Batch_num:   200] avg training loss per batch: 3.044[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.375[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.368[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.364[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.373[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.375[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.369[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.372[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.369[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.368[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.370[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.359[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.374[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.368[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.376[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.370[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.377[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.372[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.370[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.365[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.363[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.369[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.372[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.367[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.372[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.368[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.374[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.370[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.367[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.365[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.364[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.367[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.372[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.372[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.373[Epoch: 1, Batch_num:   100] avg training loss per batch: 413.559[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.370[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.369[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.373[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.367[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.355[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.368[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.359[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.353[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.350[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.337[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.344[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.341[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.327[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.329[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.327[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.301[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.244[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.234[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.218[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.197[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.204[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.187[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.188[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.190[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.179[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.175[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.171[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.163[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.173[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.161[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.163[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.169[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.164[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.159[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.155[Epoch: 1, Batch_num:   100] avg training loss per batch: 296.612[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.318[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.244[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.226[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.230[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.235[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.214[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.219[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.212[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.212[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.199[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.207[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.198[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.193[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.204[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.190[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.190[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.186[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.190[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.190[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.184[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.184[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.178[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.177[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.185[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.177[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.171[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.178[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.176[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.173[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.172[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.174[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.172[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.171[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.160[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.167[Epoch: 1, Batch_num:   100] avg training loss per batch: 9.116[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.036[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.024[Epoch: 1, Batch_num:   400] avg training loss per batch: 1.972[Epoch: 1, Batch_num:   500] avg training loss per batch: 1.955[Epoch: 1, Batch_num:   600] avg training loss per batch: 1.944[Epoch: 1, Batch_num:   700] avg training loss per batch: 1.971[Epoch: 1, Batch_num:   800] avg training loss per batch: 1.948[Epoch: 1, Batch_num:   900] avg training loss per batch: 1.952[Epoch: 2, Batch_num:   100] avg training loss per batch: 1.944[Epoch: 2, Batch_num:   200] avg training loss per batch: 1.948[Epoch: 2, Batch_num:   300] avg training loss per batch: 1.970[Epoch: 2, Batch_num:   400] avg training loss per batch: 1.949[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.242[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.235[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.222[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.199[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.204[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.183[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.187[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.172[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.191[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.172[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.166[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.172[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.261[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.166[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.165[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.161[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.150[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.144[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.173[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.156[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.158[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.144[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.130[Epoch: 1, Batch_num:   100] avg training loss per batch: 1018.325[Epoch: 1, Batch_num:   200] avg training loss per batch: 5.815[Epoch: 1, Batch_num:   300] avg training loss per batch: 5.309[Epoch: 1, Batch_num:   400] avg training loss per batch: 4.736[Epoch: 1, Batch_num:   500] avg training loss per batch: 4.181[Epoch: 1, Batch_num:   600] avg training loss per batch: 3.746[Epoch: 1, Batch_num:   700] avg training loss per batch: 3.365[Epoch: 1, Batch_num:   800] avg training loss per batch: 3.046[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.804[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.515[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.368[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.371[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.371[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.364[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.359[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.352[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.374[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.374[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.358[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.363[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.366[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.366[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.362[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.365[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.366[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.376[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.377[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.365[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.375[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.363[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.360[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.377[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.362[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.371[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.370[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.371[Epoch: 1, Batch_num:   100] avg training loss per batch: 7.814[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.369[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.367[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.363[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.369[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.378[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.379[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.369[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.358[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.364[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.372[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.368[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.367[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.378[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.367[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.365[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.372[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.371[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.375[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.373[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.371[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.375[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.365[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.369[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.369[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.372[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.363[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.370[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.371[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.368[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.373[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.367[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.361[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.373[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.373[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.372[Epoch: 1, Batch_num:   100] avg training loss per batch: 1550.051[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.114[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.098[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.018[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.003[Epoch: 1, Batch_num:   600] avg training loss per batch: 1.977[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.902[Epoch: 1, Batch_num:   800] avg training loss per batch: 3.532[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.146[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.031[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.022[Epoch: 2, Batch_num:   300] avg training loss per batch: 1.990[Epoch: 2, Batch_num:   400] avg training loss per batch: 1.991[Epoch: 2, Batch_num:   500] avg training loss per batch: 1.991[Epoch: 2, Batch_num:   600] avg training loss per batch: 1.966[Epoch: 2, Batch_num:   700] avg training loss per batch: 1.960[Epoch: 2, Batch_num:   800] avg training loss per batch: 1.966[Epoch: 2, Batch_num:   900] avg training loss per batch: 1.960[Epoch: 3, Batch_num:   100] avg training loss per batch: 1.953[Epoch: 3, Batch_num:   200] avg training loss per batch: 1.944[Epoch: 3, Batch_num:   300] avg training loss per batch: 1.949[Epoch: 3, Batch_num:   400] avg training loss per batch: 1.954[Epoch: 3, Batch_num:   500] avg training loss per batch: 1.946[Epoch: 3, Batch_num:   600] avg training loss per batch: 1.950[Epoch: 3, Batch_num:   700] avg training loss per batch: 1.942[Epoch: 3, Batch_num:   800] avg training loss per batch: 1.939[Epoch: 3, Batch_num:   900] avg training loss per batch: 1.936[Epoch: 4, Batch_num:   100] avg training loss per batch: 1.935[Epoch: 4, Batch_num:   200] avg training loss per batch: 1.940[Epoch: 4, Batch_num:   300] avg training loss per batch: 1.945[Epoch: 4, Batch_num:   400] avg training loss per batch: 1.970[Epoch: 4, Batch_num:   500] avg training loss per batch: 1.936[Epoch: 4, Batch_num:   600] avg training loss per batch: 1.925[Epoch: 4, Batch_num:   700] avg training loss per batch: 1.936[Epoch: 4, Batch_num:   800] avg training loss per batch: 1.926[Epoch: 4, Batch_num:   900] avg training loss per batch: 1.932[Epoch: 1, Batch_num:   100] avg training loss per batch: 29.930[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.262[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.230[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.217[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.191[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.182[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.165[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.164[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.166[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.164[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.125[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.148[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.221[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.191[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.152[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.141[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.132[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.166[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.131[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.130[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.115[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.110[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.112[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.108[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.098[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.091[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.112[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.081[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.082[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.100[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.086[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.077[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.077[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.087[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.089[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.074[Epoch: 1, Batch_num:   100] avg training loss per batch: 8649.719[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.333[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.303[Epoch: 1, Batch_num:   400] avg training loss per batch: 3.108[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.300[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.324[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.291[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.297[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.284[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.290[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.292[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.278[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.294[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.281[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.276[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.287[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.278[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.282[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.279[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.272[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.271[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.262[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.263[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.263[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.244[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.259[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.248[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.245[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.237[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.237[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.235[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.228[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.237[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.221[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.225[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.228[Epoch: 1, Batch_num:   100] avg training loss per batch: 63.560[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.274[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.242[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.221[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.209[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.193[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.183[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.187[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.171[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.171[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.165[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.153[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.148[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.162[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.160[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.159[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.150[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.143[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.138[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.127[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.134[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.123[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.135[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.134[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.138[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.134[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.125[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.115[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.122[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.115[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.117[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.101[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.115[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.113[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.109[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.106[Epoch: 1, Batch_num:   100] avg training loss per batch: 1791.971[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.550[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.326[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.146[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.059[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.032[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.007[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.003[Epoch: 1, Batch_num:   900] avg training loss per batch: 1.983[Epoch: 2, Batch_num:   100] avg training loss per batch: 1.996[Epoch: 2, Batch_num:   200] avg training loss per batch: 1.995[Epoch: 2, Batch_num:   300] avg training loss per batch: 1.995[Epoch: 2, Batch_num:   400] avg training loss per batch: 1.990[Epoch: 2, Batch_num:   500] avg training loss per batch: 1.989[Epoch: 2, Batch_num:   600] avg training loss per batch: 1.988[Epoch: 2, Batch_num:   700] avg training loss per batch: 1.991[Epoch: 2, Batch_num:   800] avg training loss per batch: 1.993[Epoch: 2, Batch_num:   900] avg training loss per batch: 1.991[Epoch: 3, Batch_num:   100] avg training loss per batch: 1.995[Epoch: 3, Batch_num:   200] avg training loss per batch: 1.980[Epoch: 3, Batch_num:   300] avg training loss per batch: 1.984[Epoch: 3, Batch_num:   400] avg training loss per batch: 1.982[Epoch: 3, Batch_num:   500] avg training loss per batch: 1.990[Epoch: 3, Batch_num:   600] avg training loss per batch: 1.974[Epoch: 3, Batch_num:   700] avg training loss per batch: 1.985[Epoch: 3, Batch_num:   800] avg training loss per batch: 1.972[Epoch: 3, Batch_num:   900] avg training loss per batch: 1.976[Epoch: 4, Batch_num:   100] avg training loss per batch: 1.972[Epoch: 4, Batch_num:   200] avg training loss per batch: 1.976[Epoch: 4, Batch_num:   300] avg training loss per batch: 1.973[Epoch: 4, Batch_num:   400] avg training loss per batch: 1.972[Epoch: 4, Batch_num:   500] avg training loss per batch: 1.976[Epoch: 4, Batch_num:   600] avg training loss per batch: 1.965[Epoch: 4, Batch_num:   700] avg training loss per batch: 1.971[Epoch: 4, Batch_num:   800] avg training loss per batch: 1.955[Epoch: 4, Batch_num:   900] avg training loss per batch: 1.963[Epoch: 1, Batch_num:   100] avg training loss per batch: 1718.400[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.369[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.192[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.111[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.070[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.052[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.013[Epoch: 1, Batch_num:   800] avg training loss per batch: 1.980[Epoch: 1, Batch_num:   900] avg training loss per batch: 1.979[Epoch: 2, Batch_num:   100] avg training loss per batch: 1.976[Epoch: 2, Batch_num:   200] avg training loss per batch: 1.983[Epoch: 2, Batch_num:   300] avg training loss per batch: 1.960[Epoch: 2, Batch_num:   400] avg training loss per batch: 1.971[Epoch: 2, Batch_num:   500] avg training loss per batch: 1.976[Epoch: 2, Batch_num:   600] avg training loss per batch: 1.952[Epoch: 2, Batch_num:   700] avg training loss per batch: 1.958[Epoch: 2, Batch_num:   800] avg training loss per batch: 1.955[Epoch: 2, Batch_num:   900] avg training loss per batch: 1.947[Epoch: 3, Batch_num:   100] avg training loss per batch: 1.946[Epoch: 3, Batch_num:   200] avg training loss per batch: 1.937[Epoch: 3, Batch_num:   300] avg training loss per batch: 1.934[Epoch: 3, Batch_num:   400] avg training loss per batch: 1.949[Epoch: 3, Batch_num:   500] avg training loss per batch: 1.937[Epoch: 3, Batch_num:   600] avg training loss per batch: 1.933[Epoch: 3, Batch_num:   700] avg training loss per batch: 1.940[Epoch: 3, Batch_num:   800] avg training loss per batch: 1.945[Epoch: 3, Batch_num:   900] avg training loss per batch: 1.934[Epoch: 4, Batch_num:   100] avg training loss per batch: 1.950[Epoch: 4, Batch_num:   200] avg training loss per batch: 1.939[Epoch: 4, Batch_num:   300] avg training loss per batch: 1.934[Epoch: 4, Batch_num:   400] avg training loss per batch: 1.935[Epoch: 4, Batch_num:   500] avg training loss per batch: 1.928[Epoch: 4, Batch_num:   600] avg training loss per batch: 1.929[Epoch: 4, Batch_num:   700] avg training loss per batch: 1.935[Epoch: 4, Batch_num:   800] avg training loss per batch: 1.927[Epoch: 4, Batch_num:   900] avg training loss per batch: 1.934[Epoch: 1, Batch_num:   100] avg training loss per batch: 125.971[Epoch: 1, Batch_num:   200] avg training loss per batch: 2.234[Epoch: 1, Batch_num:   300] avg training loss per batch: 2.198[Epoch: 1, Batch_num:   400] avg training loss per batch: 2.186[Epoch: 1, Batch_num:   500] avg training loss per batch: 2.174[Epoch: 1, Batch_num:   600] avg training loss per batch: 2.169[Epoch: 1, Batch_num:   700] avg training loss per batch: 2.164[Epoch: 1, Batch_num:   800] avg training loss per batch: 2.170[Epoch: 1, Batch_num:   900] avg training loss per batch: 2.153[Epoch: 2, Batch_num:   100] avg training loss per batch: 2.152[Epoch: 2, Batch_num:   200] avg training loss per batch: 2.148[Epoch: 2, Batch_num:   300] avg training loss per batch: 2.135[Epoch: 2, Batch_num:   400] avg training loss per batch: 2.150[Epoch: 2, Batch_num:   500] avg training loss per batch: 2.136[Epoch: 2, Batch_num:   600] avg training loss per batch: 2.137[Epoch: 2, Batch_num:   700] avg training loss per batch: 2.136[Epoch: 2, Batch_num:   800] avg training loss per batch: 2.132[Epoch: 2, Batch_num:   900] avg training loss per batch: 2.130[Epoch: 3, Batch_num:   100] avg training loss per batch: 2.124[Epoch: 3, Batch_num:   200] avg training loss per batch: 2.128[Epoch: 3, Batch_num:   300] avg training loss per batch: 2.125[Epoch: 3, Batch_num:   400] avg training loss per batch: 2.125[Epoch: 3, Batch_num:   500] avg training loss per batch: 2.115[Epoch: 3, Batch_num:   600] avg training loss per batch: 2.126[Epoch: 3, Batch_num:   700] avg training loss per batch: 2.117[Epoch: 3, Batch_num:   800] avg training loss per batch: 2.113[Epoch: 3, Batch_num:   900] avg training loss per batch: 2.134[Epoch: 4, Batch_num:   100] avg training loss per batch: 2.117[Epoch: 4, Batch_num:   200] avg training loss per batch: 2.114[Epoch: 4, Batch_num:   300] avg training loss per batch: 2.116[Epoch: 4, Batch_num:   400] avg training loss per batch: 2.112[Epoch: 4, Batch_num:   500] avg training loss per batch: 2.105[Epoch: 4, Batch_num:   600] avg training loss per batch: 2.104[Epoch: 4, Batch_num:   700] avg training loss per batch: 2.106[Epoch: 4, Batch_num:   800] avg training loss per batch: 2.111[Epoch: 4, Batch_num:   900] avg training loss per batch: 2.121